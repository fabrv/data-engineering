{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a9cc5b9-5fee-438a-ad9c-5fe837b284f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de cantidad de columnas por archivo:\n",
      "  15 columnas  en 48 archivos\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pathlib\n",
    "\n",
    "RAW_DIR   = Path(\"raw\")\n",
    "NULLS     = [\"\\\\N\", \"NULL\", \"\"]\n",
    "\n",
    "# capturamos solo los encabezados\n",
    "schema_largos = Counter()     \n",
    "encabezados   = {}             \n",
    "\n",
    "for csv in RAW_DIR.rglob(\"*.csv\"):\n",
    "    if \"__MACOSX\" in csv.parts:\n",
    "        continue\n",
    "    header = pl.read_csv(csv, n_rows=0, null_values=NULLS).columns\n",
    "    encabezados[csv.name] = header\n",
    "    schema_largos[len(header)] += 1\n",
    "\n",
    "print(\"Distribución de cantidad de columnas por archivo:\")\n",
    "for cols, cantidad in schema_largos.items():\n",
    "    print(f\"  {cols} columnas  en {cantidad} archivos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b41d0f9-6675-4375-b1f1-fd0b27bb35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas detectadas (normalizadas y variantes encontradas):\n",
      "\n",
      "- birth_year: ['Birth Year', 'birth year']\n",
      "- end_station_id: ['End Station ID', 'end station id']\n",
      "- end_station_latitude: ['End Station Latitude', 'end station latitude']\n",
      "- end_station_longitude: ['End Station Longitude', 'end station longitude']\n",
      "- end_station_name: ['End Station Name', 'end station name']\n",
      "- gender: ['Gender', 'gender']\n",
      "- start_station_id: ['Start Station ID', 'start station id']\n",
      "- start_station_latitude: ['Start Station Latitude', 'start station latitude']\n",
      "- start_station_longitude: ['Start Station Longitude', 'start station longitude']\n",
      "- start_station_name: ['Start Station Name', 'start station name']\n"
     ]
    }
   ],
   "source": [
    "# función snake_case para comparar\n",
    "def to_snake(s: str) -> str:\n",
    "    return s.strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "variantes = {}   # {nombre_normalizado: {variantes_originales}}\n",
    "\n",
    "for header in encabezados.values():\n",
    "    for col in header:\n",
    "        norm = to_snake(col)\n",
    "        variantes.setdefault(norm, set()).add(col)\n",
    "\n",
    "print(\"Columnas detectadas (normalizadas y variantes encontradas):\\n\")\n",
    "for norm, originals in sorted(variantes.items()):\n",
    "    if len(originals) > 1:      # solo mostramos las que cambian\n",
    "        print(f\"- {norm}: {sorted(originals)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "008b4388-960c-40a5-b650-1e55d7755b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame unido: (34383842, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>trip_duration</th><th>start_time</th><th>stop_time</th><th>start_station_id</th><th>start_station_name</th><th>start_station_latitude</th><th>start_station_longitude</th><th>end_station_id</th><th>end_station_name</th><th>end_station_latitude</th><th>end_station_longitude</th><th>bike_id</th><th>user_type</th><th>birth_year</th><th>gender</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>str</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>457</td><td>&quot;2017-10-01 00:00:00&quot;</td><td>&quot;2017-10-01 00:07:38&quot;</td><td>479</td><td>&quot;9 Ave &amp; W 45 St&quot;</td><td>40.760193</td><td>-73.991255</td><td>478</td><td>&quot;11 Ave &amp; W 41 St&quot;</td><td>40.760301</td><td>-73.998842</td><td>30951</td><td>&quot;Subscriber&quot;</td><td>1985.0</td><td>1</td></tr><tr><td>6462</td><td>&quot;2017-10-01 00:00:20&quot;</td><td>&quot;2017-10-01 01:48:03&quot;</td><td>279</td><td>&quot;Peck Slip &amp; Front St&quot;</td><td>40.707873</td><td>-74.00167</td><td>307</td><td>&quot;Canal St &amp; Rutgers St&quot;</td><td>40.714275</td><td>-73.9899</td><td>14809</td><td>&quot;Customer&quot;</td><td>null</td><td>0</td></tr><tr><td>761</td><td>&quot;2017-10-01 00:00:27&quot;</td><td>&quot;2017-10-01 00:13:09&quot;</td><td>504</td><td>&quot;1 Ave &amp; E 16 St&quot;</td><td>40.732219</td><td>-73.981656</td><td>350</td><td>&quot;Clinton St &amp; Grand St&quot;</td><td>40.715595</td><td>-73.98703</td><td>28713</td><td>&quot;Subscriber&quot;</td><td>1992.0</td><td>1</td></tr><tr><td>1193</td><td>&quot;2017-10-01 00:00:29&quot;</td><td>&quot;2017-10-01 00:20:22&quot;</td><td>3236</td><td>&quot;W 42 St &amp; Dyer Ave&quot;</td><td>40.758985</td><td>-73.9938</td><td>3233</td><td>&quot;E 48 St &amp; 5 Ave&quot;</td><td>40.757246</td><td>-73.978059</td><td>16008</td><td>&quot;Customer&quot;</td><td>1992.0</td><td>2</td></tr><tr><td>2772</td><td>&quot;2017-10-01 00:00:32&quot;</td><td>&quot;2017-10-01 00:46:44&quot;</td><td>2006</td><td>&quot;Central Park S &amp; 6 Ave&quot;</td><td>40.765909</td><td>-73.976342</td><td>469</td><td>&quot;Broadway &amp; W 53 St&quot;</td><td>40.763441</td><td>-73.982681</td><td>14556</td><td>&quot;Customer&quot;</td><td>null</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 15)\n",
       "┌───────────────┬─────────────────────┬─────────────────────┬──────────────────┬───┬─────────┬────────────┬────────────┬────────┐\n",
       "│ trip_duration ┆ start_time          ┆ stop_time           ┆ start_station_id ┆ … ┆ bike_id ┆ user_type  ┆ birth_year ┆ gender │\n",
       "│ ---           ┆ ---                 ┆ ---                 ┆ ---              ┆   ┆ ---     ┆ ---        ┆ ---        ┆ ---    │\n",
       "│ i64           ┆ str                 ┆ str                 ┆ i64              ┆   ┆ i64     ┆ str        ┆ f64        ┆ i64    │\n",
       "╞═══════════════╪═════════════════════╪═════════════════════╪══════════════════╪═══╪═════════╪════════════╪════════════╪════════╡\n",
       "│ 457           ┆ 2017-10-01 00:00:00 ┆ 2017-10-01 00:07:38 ┆ 479              ┆ … ┆ 30951   ┆ Subscriber ┆ 1985.0     ┆ 1      │\n",
       "│ 6462          ┆ 2017-10-01 00:00:20 ┆ 2017-10-01 01:48:03 ┆ 279              ┆ … ┆ 14809   ┆ Customer   ┆ null       ┆ 0      │\n",
       "│ 761           ┆ 2017-10-01 00:00:27 ┆ 2017-10-01 00:13:09 ┆ 504              ┆ … ┆ 28713   ┆ Subscriber ┆ 1992.0     ┆ 1      │\n",
       "│ 1193          ┆ 2017-10-01 00:00:29 ┆ 2017-10-01 00:20:22 ┆ 3236             ┆ … ┆ 16008   ┆ Customer   ┆ 1992.0     ┆ 2      │\n",
       "│ 2772          ┆ 2017-10-01 00:00:32 ┆ 2017-10-01 00:46:44 ┆ 2006             ┆ … ┆ 14556   ┆ Customer   ┆ null       ┆ 0      │\n",
       "└───────────────┴─────────────────────┴─────────────────────┴──────────────────┴───┴─────────┴────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_DIR = Path(\"raw\")\n",
    "NULLS   = [\"\\\\N\", \"NULL\", \"\"]\n",
    "\n",
    "# Sinonimospara que coincidan los headers\n",
    "SYNONYMS = {\n",
    "    \"tripduration\": \"trip_duration\",\n",
    "    \"trip_duration_seconds\": \"trip_duration\",\n",
    "    \"bikeid\": \"bike_id\",\n",
    "    \"starttime\": \"start_time\",\n",
    "    \"started_at\": \"start_time\",\n",
    "    \"stoptime\": \"stop_time\",\n",
    "    \"ended_at\": \"stop_time\",\n",
    "    \"usertype\": \"user_type\",\n",
    "    \"birth year\": \"birth_year\",\n",
    "}\n",
    "\n",
    "def normalize(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.rename({c: c.strip().lower().replace(\" \", \"_\") for c in df.columns})\n",
    "    df = df.rename({c: SYNONYMS.get(c, c) for c in df.columns})\n",
    "    return df\n",
    "\n",
    "dfs = []\n",
    "for csv in RAW_DIR.rglob(\"*.csv\"):\n",
    "    if \"__MACOSX\" in csv.parts:\n",
    "        continue\n",
    "    part = pl.read_csv(csv, null_values=NULLS, infer_schema_length=10_000)\n",
    "    dfs.append(normalize(part))\n",
    "\n",
    "#union\n",
    "df = pl.concat(dfs, how=\"vertical_relaxed\")\n",
    "print(\"DataFrame unido:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e460148-4f99-41f3-92e9-74ecb892a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_duration        : Int64\n",
      "start_time           : String\n",
      "stop_time            : String\n",
      "start_station_id     : Int64\n",
      "start_station_name   : String\n",
      "start_station_latitude : Float64\n",
      "start_station_longitude : Float64\n",
      "end_station_id       : Int64\n",
      "end_station_name     : String\n",
      "end_station_latitude : Float64\n",
      "end_station_longitude : Float64\n",
      "bike_id              : Int64\n",
      "user_type            : String\n",
      "birth_year           : Float64\n",
      "gender               : Int64\n"
     ]
    }
   ],
   "source": [
    "for name, dtype in df.schema.items():\n",
    "    print(f\"{name:<20} : {dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aeb2144-3054-46d9-83a3-453c17f49c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birth_year                -> 3735425\n",
      "user_type                 -> 15909\n"
     ]
    }
   ],
   "source": [
    "nulls_df = df.null_count()                       \n",
    "\n",
    "# Lo pasamos a diccionario\n",
    "nulls_dict = {col: int(nulls_df[col][0]) for col in df.columns}\n",
    "\n",
    "for col, n in sorted(nulls_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    if n > 0:\n",
    "        print(f\"{col:<25} -> {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1464e95-e5c0-4a4b-b217-1d1bdd758db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_duration       : Int64\n",
      "start_time          : Datetime(time_unit='us', time_zone=None)\n",
      "stop_time           : Datetime(time_unit='us', time_zone=None)\n",
      "start_station_id    : Int64\n",
      "start_station_name  : String\n",
      "start_station_latitude: Float64\n",
      "start_station_longitude: Float64\n",
      "end_station_id      : Int64\n",
      "end_station_name    : String\n",
      "end_station_latitude: Float64\n",
      "end_station_longitude: Float64\n",
      "bike_id             : Int64\n",
      "user_type           : String\n",
      "birth_year          : Int64\n",
      "gender              : Int64\n"
     ]
    }
   ],
   "source": [
    "df_clean = (\n",
    "    df\n",
    "    # fechas\n",
    "    .with_columns([\n",
    "        # start_time\n",
    "        pl.coalesce([\n",
    "            pl.col(\"start_time\").cast(pl.Utf8, strict=False)\n",
    "              .str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\", strict=False, exact=False),\n",
    "            pl.col(\"start_time\").cast(pl.Utf8, strict=False)\n",
    "              .str.strptime(pl.Datetime, \"%m/%d/%Y %H:%M:%S\", strict=False, exact=False)\n",
    "        ]).alias(\"start_time\"),\n",
    "\n",
    "        # stop_time\n",
    "        pl.coalesce([\n",
    "            pl.col(\"stop_time\").cast(pl.Utf8, strict=False)\n",
    "              .str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\", strict=False, exact=False),\n",
    "            pl.col(\"stop_time\").cast(pl.Utf8, strict=False)\n",
    "              .str.strptime(pl.Datetime, \"%m/%d/%Y %H:%M:%S\", strict=False, exact=False)\n",
    "        ]).alias(\"stop_time\"),\n",
    "    ])\n",
    "    #birth_year\n",
    "    .with_columns(\n",
    "        pl.col(\"birth_year\")\n",
    "          .cast(pl.Float64, strict=False)          \n",
    "          .cast(pl.Int64,  strict=False)        \n",
    "    )\n",
    ")\n",
    "\n",
    "for name, dtype in df_clean.schema.items():\n",
    "    print(f\"{name:<20}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4636ec99-d039-4626-9ec4-23cd03d34696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings vacíos restantes por columna:\n",
      "shape: (1, 3)\n",
      "┌────────────────────┬──────────────────┬───────────┐\n",
      "│ start_station_name ┆ end_station_name ┆ user_type │\n",
      "│ ---                ┆ ---              ┆ ---       │\n",
      "│ u32                ┆ u32              ┆ u32       │\n",
      "╞════════════════════╪══════════════════╪═══════════╡\n",
      "│ 0                  ┆ 0                ┆ 0         │\n",
      "└────────────────────┴──────────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "#columnas de tipo texto\n",
    "str_cols = [c for c, t in df_clean.schema.items() if t == pl.Utf8]\n",
    "\n",
    "#reemplazar \"\"  por null y recortar\n",
    "df_clean = df_clean.with_columns([\n",
    "    pl.when(\n",
    "        pl.col(c).cast(pl.Utf8, strict=False).str.strip_chars() == \"\"\n",
    "    )\n",
    "    .then(pl.lit(None))\n",
    "    .otherwise(\n",
    "        pl.col(c).cast(pl.Utf8, strict=False).str.strip_chars()\n",
    "    )\n",
    "    .alias(c)\n",
    "    for c in str_cols\n",
    "])\n",
    "\n",
    "#conteo de strings vacíos que todavía existan \n",
    "vacíos = df_clean.select([\n",
    "    (pl.col(c) == \"\").sum().alias(c) for c in str_cols\n",
    "])\n",
    "\n",
    "print(\"Strings vacíos restantes por columna:\")\n",
    "print(vacíos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8964e620-5789-4bdd-8a41-a345254b2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time                -> 9420380\n",
      "stop_time                 -> 9420175\n",
      "birth_year                -> 3735425\n",
      "user_type                 -> 15909\n"
     ]
    }
   ],
   "source": [
    "#nuevo conteo de vacios\n",
    "nulls_df = df_clean.null_count()                       \n",
    "\n",
    "#lo pasamos a diccionario\n",
    "nulls_dict = {col: int(nulls_df[col][0]) for col in df.columns}\n",
    "\n",
    "for col, n in sorted(nulls_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    if n > 0:\n",
    "        print(f\"{col:<25} -> {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e4ad9ed-fa59-4b2a-b8c3-cd192bb126ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados con clave compuesta: 6897879\n",
      "Filas tras deduplicar: 27485963\n"
     ]
    }
   ],
   "source": [
    "#Eliminacion de duplicados\n",
    "subset = [\"start_time\", \"bike_id\", \"start_station_id\", \"stop_time\"]\n",
    "\n",
    "dup_total = len(df_clean) - df_clean.unique(subset=subset).shape[0]\n",
    "print(\"Duplicados con clave compuesta:\", dup_total)\n",
    "\n",
    "if dup_total:\n",
    "    df_clean = df_clean.unique(subset=subset, keep=\"first\")\n",
    "    print(\"Filas tras deduplicar:\", df_clean.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb208bc8-7c36-4349-8b9c-750273560e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validaciones basicas\n",
      "Duración ≤ 0 seg.        : 0\n",
      "stop_time < start_time   : 49\n",
      "Filas descartadas por inconsistencia temporal : 49\n",
      "Filas finales tras depurar                 : 24962830\n"
     ]
    }
   ],
   "source": [
    "#reglas simples de coherencia\n",
    "neg_dur   = (df_clean['trip_duration'] <= 0).sum()\n",
    "bad_order = (df_clean['stop_time'] < df_clean['start_time']).sum()\n",
    "\n",
    "print(\"Validaciones basicas\")\n",
    "print(f\"Duración ≤ 0 seg.        : {neg_dur}\")\n",
    "print(f\"stop_time < start_time   : {bad_order}\")\n",
    "\n",
    "#quitat filas stop_time < start_time\n",
    "bad_mask   = df_clean['stop_time'] < df_clean['start_time']\n",
    "bad_count  = bad_mask.sum()\n",
    "\n",
    "print(\"Filas descartadas por inconsistencia temporal :\", bad_count)\n",
    "\n",
    "df_clean = df_clean.filter(~bad_mask)\n",
    "print(\"Filas finales tras depurar                 :\", df_clean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42013564-814a-420a-9daa-3a106c150de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset\n",
      "Filas     : 24,962,830\n",
      "Columnas  : 15\n",
      "\n",
      "Nulos por columna\n",
      "birth_year                ->    2509115  (10.05 %)\n",
      "user_type                 ->      15909  ( 0.06 %)\n"
     ]
    }
   ],
   "source": [
    "row_cnt, col_cnt = df_clean.shape\n",
    "print(\"Tamaño del dataset\")\n",
    "print(f\"Filas     : {row_cnt:,}\")\n",
    "print(f\"Columnas  : {col_cnt}\\n\")\n",
    "\n",
    "print(\"Nulos por columna\")\n",
    "nulls_df = df_clean.null_count()\n",
    "nulls_dict = {col: int(nulls_df[col][0]) for col in df_clean.columns}\n",
    "\n",
    "for col, n in sorted(nulls_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    if n:                                       \n",
    "        pct = n * 100 / row_cnt\n",
    "        print(f\"{col:<25} -> {n:>10}  ({pct:5.2f} %)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7c19eed-9a05-4add-9a7e-1eb3ca65c0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet listo en clean/citibike_phase1.parquet\n"
     ]
    }
   ],
   "source": [
    "#Enviar a un parquet\n",
    "pathlib.Path(\"clean\").mkdir(exist_ok=True) \n",
    "\n",
    "df_clean.write_parquet(\n",
    "    \"clean/citibike_phase1.parquet\",\n",
    "    compression=\"snappy\"\n",
    ")\n",
    "\n",
    "print(\"Parquet listo en clean/citibike_phase1.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
